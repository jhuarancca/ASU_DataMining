{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMD66sbfr8rAThY2O64940D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhuarancca/ASU_DataMining/blob/main/DataMininProyecto03_ver02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDAgFEBQ-tVK",
        "outputId": "c2fbb073-d8d2-4973-ed84-c91469521891"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max meal value (grams): 122.0\n",
            "Min meal value (grams): 3.0\n",
            "In total you should have N = ( 122.0 - 3.0 / 20) i.e. 6 bins\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: Mean of empty slice.\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in true_divide\n",
            "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: Mean of empty slice.\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in true_divide\n",
            "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import numpy as np  \n",
        "import math\n",
        "\n",
        "from scipy.stats import skew, kurtosis, entropy\n",
        "from sklearn.cluster import DBSCAN, KMeans\n",
        "from sklearn.metrics.cluster import contingency_matrix\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.metrics import cluster, silhouette_score, v_measure_score, adjusted_rand_score, completeness_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def calculatePurity(groundTruth, labels):\n",
        "    # compute contingency matrix (also called confusion matrix)\n",
        "    cont_mat = contingency_matrix(groundTruth, labels)\n",
        "    # return purity\n",
        "    return np.sum(np.amax(cont_mat, axis=0)) / np.sum(cont_mat)\n",
        "\n",
        "\n",
        "def calculateSSE(X, labels,n):\n",
        "    sse = 0\n",
        "    for i in range(n):\n",
        "        cluster = X[labels == i]\n",
        "        mean = cluster.mean(axis=0)\n",
        "        sse += ((cluster - mean) ** 2).sum()\n",
        "    return sse\n",
        "\n",
        "\n",
        "def calculateEntropy(groundTruth, labels, n):\n",
        "    ent = 0\n",
        "    for i in range(n):\n",
        "        bincount = np.bincount(groundTruth[labels == i])\n",
        "        w = (labels == i).sum()\n",
        "        probabilities = bincount[bincount != 0] / w\n",
        "        ent += entropy(probabilities) * w / labels.shape[0]\n",
        "    return ent\n",
        "\n",
        "\n",
        "bins = {1:[0,20],2:[21,40],3:[41,60],4:[61,80],5:[81,100],6:[101,120]}\n",
        "\n",
        "def getBin(mealAmountGrams):\n",
        "    lint_bin = 0\n",
        "    li_binNumber =1\n",
        "    for bin_number, bin_range in bins.items():\n",
        "        if bin_range[0]<=mealAmountGrams<=bin_range[1]:\n",
        "            li_binNumber = bin_number\n",
        "    return li_binNumber\n",
        "\n",
        "dfIns = pd.read_csv ('InsulinData.csv', low_memory=False)\n",
        "dfCGM = pd.read_csv ('CGMData.csv', low_memory=False)\n",
        "\n",
        "\n",
        "dfIns['Datetime']=pd.to_datetime(dfIns['Date'] + ' ' + dfIns['Time'])\n",
        "dfCGM['Datetime']=pd.to_datetime(dfCGM['Date'] + ' ' + dfCGM['Time'])\n",
        "dfIns.rename(columns={\"BWZ Carb Input (grams)\": \"Carb\"},inplace=True)\n",
        "\n",
        "dfMeals=dfIns\n",
        "dfMeals=dfMeals.drop(dfMeals[dfMeals['Carb'].isna()].index)\n",
        "dfMeals = dfMeals.drop(dfMeals[(dfMeals['Carb']==0.0)].index)\n",
        "dfMeals=dfMeals[[\"Datetime\", \"Carb\"]]\n",
        "dfMeals=dfMeals.reset_index(drop=True)\n",
        "dfMeals = dfMeals.sort_values(by=['Datetime'], ascending=True)\n",
        "dfMeals['Delete']='N'\n",
        "\n",
        "\n",
        "dfMealsTmp=dfMeals\n",
        "dfMealsTmp = dfMealsTmp.sort_values(by=['Datetime'], ascending=True)\n",
        "dfMealsTmp=dfMealsTmp.reset_index(drop=True)\n",
        "\n",
        "for index, row in dfMealsTmp.iterrows():\n",
        "   ld_DateTime1=dfMealsTmp.at[index, 'Datetime']\n",
        "   \n",
        "   if index<(len(dfMealsTmp.index)-1):\n",
        "    #print(index,len(dfMeals.index))\n",
        "    ld_DateTime2=dfMealsTmp.at[index+1,'Datetime']\n",
        "    ld_DateTime3=ld_DateTime1  + timedelta(hours=2)\n",
        "    if ld_DateTime2<=ld_DateTime3:\n",
        "      dfMeals.at[index,'Delete']='Y'\n",
        "      #print(index,row['Datetime'], row['Carb'],ld_DateTime2,ld_DateTime3)\n",
        "dfMeals01=dfMeals[(dfMeals['Delete']=='N')]\n",
        "dfMeals01=dfMeals01.reset_index(drop=True)\n",
        "\n",
        "maxMeal = max(dfMeals01['Carb'])\n",
        "minMeal = min(dfMeals01['Carb'])\n",
        "\n",
        "print(\"Max meal value (grams):\", maxMeal)\n",
        "print(\"Min meal value (grams):\", minMeal)\n",
        "\n",
        "binsNumber = math.ceil((maxMeal-minMeal)/20)\n",
        "print(\"In total you should have N = (\",maxMeal,\"-\",minMeal,\"/ 20) i.e.\", binsNumber, \"bins\")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "dfMeals01[\"CarbScaled\"] = scaler.fit_transform(dfMeals01['Carb'].values.reshape(-1,1))\n",
        "\n",
        "dfMeals01['GroundTruth'] = dfMeals01['Carb'].apply(lambda x: getBin(x)) \n",
        "#dfMeals01[\"GroundTruth\"].value_counts().sort_values(ascending=True).plot(kind=\"barh\")\n",
        "\n",
        "X = dfMeals01[\"CarbScaled\"].values.reshape(-1,1)\n",
        "\n",
        "kmeans = KMeans(n_clusters=5, random_state=42, max_iter=100)\n",
        "kmeans_model = kmeans.fit(X)\n",
        "kmeans_silhouette = silhouette_score(X, kmeans.labels_).round(2)\n",
        "\n",
        "# Create a column of K-means Prediction\n",
        "dfMeals01['KmeanCluster'] = kmeans_model.predict(X)\n",
        "# Calculate accuracy using entropy, purity_score, & v-measure score\n",
        "kmeanEntropy = calculateEntropy(dfMeals01['GroundTruth'],dfMeals01['KmeanCluster'],binsNumber)\n",
        "kmeanPurity = calculatePurity(dfMeals01['GroundTruth'],dfMeals01['KmeanCluster'])\n",
        "kmeanSSE = calculateSSE(X, kmeans.labels_,binsNumber)\n",
        "\n",
        "# Define a model\n",
        "dbscan = DBSCAN(eps=0.3)\n",
        "dbscan_model = dbscan.fit(X)\n",
        "dbscan_silhouette = silhouette_score(X, dbscan_model.labels_).round(2)\n",
        "dfMeals01['DBSCAN_Cluster'] = dbscan_model.fit_predict(X)\n",
        "\n",
        "# Calculate accuracy using entropy, purity_score, & v-measure score\n",
        "dbscanEntropy = calculateEntropy(dfMeals01['GroundTruth'],dfMeals01['DBSCAN_Cluster'],binsNumber)\n",
        "dbscanPurity = calculatePurity(dfMeals01['GroundTruth'],dfMeals01['DBSCAN_Cluster'])\n",
        "dbscanSSE = calculateSSE(X, dbscan.labels_,binsNumber)\n",
        "\n",
        "#dsResult = {}\n",
        "#dsResult['SSE for Kmeans'] =  \"%.2f\"%kmeanSSE\n",
        "#dsResult['SSE for DBSCAN'] =  \"%.2f\"%dbscanSSE\n",
        "#dsResult['Entropy for Kmeans'] =  \"%.2f\"%kmeanEntropy\n",
        "#dsResult['Entropy for DBSCAN'] =  \"%.2f\"%dbscanEntropy\n",
        "#dsResult['Purity for K means'] =  \"%.2f\"%kmeanPurity\n",
        "#dsResult['Purity for DBSCAN'] =  \"%.2f\"%dbscanPurity\n",
        "\n",
        "#dsResult = pd.DataFrame(dsResult, index=[0])\n",
        "#dsResult.to_csv('Result.csv',index=False)\n",
        "#dsResult\n",
        "###\n",
        "#Report your accuracy of clustering based on SSE, entropy and purity metrics.\n",
        "cols = ['SSE Kmeans', 'SSE DBSCAN', 'Entropy Kmeans','Entropy DBSCAN', 'Purity Kmeans', 'Purity DBSCAN']\n",
        "rows = [[kmeanSSE, dbscanSSE,kmeanEntropy, dbscanEntropy,kmeanPurity, dbscanPurity]]\n",
        "\n",
        "df = pd.DataFrame(rows, columns=cols)\n",
        "df.to_csv('Result.csv',index=False, header=False)\n",
        "\n"
      ]
    }
  ]
}